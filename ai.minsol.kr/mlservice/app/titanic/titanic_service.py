"""
íƒ€ì´íƒ€ë‹‰ ë°ì´í„° ì„œë¹„ìŠ¤
íŒë‹¤ìŠ¤, ë„˜íŒŒì´, ì‚¬ì´í‚·ëŸ°ì„ ì‚¬ìš©í•œ ë°ì´í„° ì²˜ë¦¬ ë° ë¨¸ì‹ ëŸ¬ë‹ ì„œë¹„ìŠ¤
"""
import sys
import logging
from pathlib import Path
from typing import List, Dict, Optional, Any, ParamSpecArgs
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.naive_bayes import GaussianNB
from sklearn.svm import SVC
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
import joblib
from app.titanic.titanic_method import TitanicMethod
from app.titanic.titanic_dataset import TitanicDataSet

class TitanicService:
    """íƒ€ì´íƒ€ë‹‰ ë°ì´í„° ì²˜ë¦¬ ë° ë¨¸ì‹ ëŸ¬ë‹ ì„œë¹„ìŠ¤"""
    
    def __init__(self):
        # CSV íŒŒì¼ ê²½ë¡œ ì„¤ì • (resources/titanic ë””ë ‰í† ë¦¬ ê¸°ì¤€)
        self.titanic_dir = Path(__file__).parent.parent / 'resources' / 'titanic'
        self.titanic_dir = self.titanic_dir.resolve()  # ì ˆëŒ€ ê²½ë¡œë¡œ ë³€í™˜
        self.train_csv_path = self.titanic_dir / 'train.csv'
        self.test_csv_path = self.titanic_dir / 'test.csv'
        # Logger ì„¤ì •
        self.logger = logging.getLogger(__name__)
        
        self.logger.info(f"CSV íŒŒì¼ ê²½ë¡œ í™•ì¸ ì™„ë£Œ - Train: {self.train_csv_path}, Test: {self.test_csv_path}")
        # ì „ì²˜ë¦¬ëœ ë°ì´í„° ì €ì¥
        self.dataset = None
        self.X_train = None
        self.X_test = None
        self.y_train = None
        # ëª¨ë¸ ì €ì¥
        self.models = {}

    def preprocess(self):
        self.logger.info("â¤ï¸â¤ï¸ Train ì „ì²˜ë¦¬ ì‹œì‘") 
        self.logger.info(f"Train CSV ê²½ë¡œ: {self.train_csv_path}")
        self.logger.info(f"Test CSV ê²½ë¡œ: {self.test_csv_path}")
        
        try:
            the_method = TitanicMethod()
            df_train = the_method.read_csv(str(self.train_csv_path))
            df_test = the_method.read_csv(str(self.test_csv_path))
        except FileNotFoundError as e:
            self.logger.error(f"CSV íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {str(e)}")
            raise
        except Exception as e:
            self.logger.error(f"CSV íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {str(e)}")
            raise
        this_train = the_method.create_df(df_train, 'Survived')

        # test ë°ì´í„°ì—ëŠ” Survived ì»¬ëŸ¼ì´ ì—†ìœ¼ë¯€ë¡œ ê·¸ëŒ€ë¡œ ì‚¬ìš©
        this_test = df_test.copy()
        self.logger.info(f'1. Train ì˜ type \n {type(this_train)} ')
        self.logger.info(f'2. Train ì˜ column \n {this_train.columns} ')
        self.logger.info(f'3. Train ì˜ ìƒìœ„ 5ê°œ í–‰\n {this_train.head(5)} ')
        self.logger.info(f'4. Train ì˜ null ì˜ ê°¯ìˆ˜\n {int(this_train.isnull().sum().sum())}ê°œ')
        self.logger.info("ğŸ’™ğŸ’™ Test ì „ì²˜ë¦¬ ì‹œì‘")
        # test ë°ì´í„°ì—ëŠ” Survived ì»¬ëŸ¼ì´ ì—†ìœ¼ë¯€ë¡œ ê·¸ëŒ€ë¡œ ì‚¬ìš©
        self.logger.info(f'1. Test ì˜ type \n {type(this_test)}')
        self.logger.info(f'2. Test ì˜ column \n {this_test.columns}')
        self.logger.info(f'3. Test ì˜ ìƒìœ„ 5ê°œ í–‰\n {this_test.head(5)}')
        self.logger.info(f'4. Test ì˜ null ì˜ ê°¯ìˆ˜\n {int(this_test.isnull().sum().sum())}ê°œ')

        this = TitanicDataSet()
        this.train = this_train
        this.test = this_test

        drop_features = ['SibSp', 'Parch', 'Cabin', 'Ticket']
        this = the_method.drop_feature(this, *drop_features)
        this.train = the_method.pclass_ordinal(this.train)
        this.test = the_method.pclass_ordinal(this.test)
        this.train = the_method.gender_nominal(this.train)
        this.test = the_method.gender_nominal(this.test)
        this.train = the_method.age_ratio(this.train)
        this.test = the_method.age_ratio(this.test)
        this.train = the_method.fare_ordinal(this.train)
        this.test = the_method.fare_ordinal(this.test)
        this.train = the_method.embarked_ordinal(this.train)
        this.test = the_method.embarked_ordinal(this.test)
        this.train = the_method.title_nominal(this.train)
        this.test = the_method.title_nominal(this.test)
        drop_name = ['Name']
        this = the_method.drop_feature(this, *drop_name)
        
        # this ê°ì²´ì—ì„œ ë‹¤ì‹œ ë³€ìˆ˜ë¡œ í• ë‹¹
        this_train = this.train
        this_test = this.test

        self.logger.info("â¤ï¸â¤ï¸ Train ì „ì²˜ë¦¬ ì™„ë£Œ")
        self.logger.info(f'1. Train ì˜ type \n {type(this_train)} ')
        self.logger.info(f'2. Train ì˜ column \n {this_train.columns} ')
        self.logger.info(f'3. Train ì˜ ìƒìœ„ 5ê°œ í–‰\n {this_train.head(5)} ')
        self.logger.info(f'4. Train ì˜ null ì˜ ê°¯ìˆ˜\n {int(this_train.isnull().sum().sum())}ê°œ')
        self.logger.info("ğŸ’™ğŸ’™ Test ì „ì²˜ë¦¬ ì™„ë£Œ")
        self.logger.info(f'1. Test ì˜ type \n {type(this_test)} ')
        self.logger.info(f'2. Test ì˜ column \n {this_test.columns} ')
        self.logger.info(f'3. Test ì˜ ìƒìœ„ 5ê°œ í–‰\n {this_test.head(5)} ')
        self.logger.info(f'4. Test ì˜ null ì˜ ê°¯ìˆ˜\n {int(this_test.isnull().sum().sum())}ê°œ')
        
        # ì „ì²˜ë¦¬ëœ ë°ì´í„° ì €ì¥
        self.dataset = this
        # ì›ë³¸ train ë°ì´í„°ì—ì„œ label ì¶”ì¶œ
        df_train_original = the_method.read_csv(str(self.train_csv_path))
        y_train = df_train_original['Survived']
        # ì „ì²˜ë¦¬ëœ train ë°ì´í„°ë¥¼ featureë¡œ ì‚¬ìš©
        self.X_train = this_train
        self.X_test = this_test
        self.y_train = y_train

    def modeling(self):
        self.logger.info("ğŸ€ğŸ€ ëª¨ë¸ë§ ì‹œì‘")

        # ëª¨ë¸ ì´ˆê¸°í™”
        self.models = {
            'logistic_regression': LogisticRegression(random_state=42, max_iter=1000),
            'naive_bayes': GaussianNB(),
            'random_forest': RandomForestClassifier(n_estimators=100, random_state=42),
            'svm': SVC(random_state=42, probability=True)
        }
        
        # LightGBMì´ ì‚¬ìš© ê°€ëŠ¥í•œ ê²½ìš° ì¶”ê°€ (ì§€ì—° import)
        try:
            import lightgbm as lgb
            self.models['lightgbm'] = lgb.LGBMClassifier(random_state=42, verbose=-1)
            self.logger.info("LightGBM ëª¨ë¸ ì¶”ê°€ë¨")
        except (ImportError, OSError) as e:
            # ImportError: íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì€ ê²½ìš°
            # OSError: ì‹œìŠ¤í…œ ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì—†ëŠ” ê²½ìš° (libgomp.so.1 ë“±)
            self.logger.warning(f"LightGBMì´ ì‚¬ìš© ë¶ˆê°€ëŠ¥í•˜ì—¬ ì œì™¸ë©ë‹ˆë‹¤: {str(e)}")

        self.logger.info("ğŸ€ğŸ€ ëª¨ë¸ë§ ì™„ë£Œ")

    def learning(self):
        self.logger.info("ğŸ€ğŸ€ í•™ìŠµ ì‹œì‘")

        if self.X_train is None or self.y_train is None:
            self.logger.error("ì „ì²˜ë¦¬ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € preprocess()ë¥¼ ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
            return

        # ëª¨ë¸ì´ ì´ˆê¸°í™”ë˜ì§€ ì•Šì€ ê²½ìš° ì´ˆê¸°í™”
        if not self.models:
            self.modeling()

        # ê° ëª¨ë¸ í•™ìŠµ
        for model_name, model in self.models.items():
            self.logger.info(f"{model_name} í•™ìŠµ ì‹œì‘...")
            model.fit(self.X_train, self.y_train)
            self.logger.info(f"{model_name} í•™ìŠµ ì™„ë£Œ")

        self.logger.info("ğŸ€ğŸ€ í•™ìŠµ ì™„ë£Œ")

    def evaluate(self):
        self.logger.info("ğŸ€ğŸ€ í‰ê°€ ì‹œì‘")
        
        if not self.models:
            self.logger.error("í•™ìŠµëœ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € learning()ì„ ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
            return {}
        
        if self.X_train is None or self.y_train is None:
            self.logger.error("ì „ì²˜ë¦¬ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € preprocess()ë¥¼ ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
            return {}

        # train ë°ì´í„°ë¥¼ train/validationìœ¼ë¡œ ë¶„í• 
        X_train_split, X_val_split, y_train_split, y_val_split = train_test_split(
            self.X_train, self.y_train, test_size=0.2, random_state=42, stratify=self.y_train
        )

        results = {}
        
        # ê° ëª¨ë¸ í‰ê°€
        for model_name, model in self.models.items():
            # í•™ìŠµ (validation setìœ¼ë¡œ í‰ê°€í•˜ê¸° ìœ„í•´)
            model.fit(X_train_split, y_train_split)
            # ì˜ˆì¸¡
            y_pred = model.predict(X_val_split)
            # ì •í™•ë„ ê³„ì‚°
            accuracy = accuracy_score(y_val_split, y_pred)
            results[model_name] = accuracy
            
            # í•œê¸€ ì´ë¦„ ë§¤í•‘
            model_name_kr = {
                'logistic_regression': 'ë¡œì§€ìŠ¤í‹± íšŒê·€',
                'naive_bayes': 'ë‚˜ì´ë¸Œë² ì´ì¦ˆ',
                'random_forest': 'ëœë¤í¬ë ˆìŠ¤íŠ¸',
                'lightgbm': 'LightGBM',
                'svm': 'SVM'
            }.get(model_name, model_name)
            
            self.logger.info(f'{model_name_kr} í™œìš©í•œ ê²€ì¦ ì •í™•ë„: {accuracy:.4f}')

        self.logger.info("ğŸ€ğŸ€ í‰ê°€ ì™„ë£Œ")
        return results

    def submit(self):
        self.logger.info("ğŸ€ğŸ€ ì œì¶œ ì‹œì‘")
        
        if self.X_train is None or self.y_train is None or self.X_test is None:
            self.logger.error("ì „ì²˜ë¦¬ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € preprocess()ë¥¼ ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
            return None
        
        if not self.models:
            self.logger.error("í•™ìŠµëœ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € learning()ì„ ì‹¤í–‰í•´ì£¼ì„¸ìš”.")
            return None
        
        # í‰ê°€ë¥¼ í†µí•´ ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì„ íƒ
        self.logger.info("ëª¨ë¸ í‰ê°€ë¥¼ í†µí•´ ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì„ íƒ ì¤‘...")
        results = self.evaluate()
        
        if not results:
            self.logger.error("í‰ê°€ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return None
        
        # ìµœê³  ì •í™•ë„ ëª¨ë¸ ì„ íƒ
        best_model_name = max(results, key=results.get)
        best_accuracy = results[best_model_name]
        
        self.logger.info(f"ìµœê³  ì„±ëŠ¥ ëª¨ë¸: {best_model_name} (ì •í™•ë„: {best_accuracy:.4f})")
        
        # ìµœê³  ëª¨ë¸ë¡œ ì „ì²´ train ë°ì´í„° ì¬í•™ìŠµ
        best_model = self.models[best_model_name]
        self.logger.info(f"{best_model_name}ë¡œ ì „ì²´ train ë°ì´í„° ì¬í•™ìŠµ ì¤‘...")
        best_model.fit(self.X_train, self.y_train)
        
        # test ë°ì´í„° ì˜ˆì¸¡
        self.logger.info("test ë°ì´í„° ì˜ˆì¸¡ ì¤‘...")
        predictions = best_model.predict(self.X_test)
        
        # PassengerId ì¶”ì¶œ (test ë°ì´í„°ì—ì„œ)
        passenger_ids = self.X_test['PassengerId'].values
        
        # ì œì¶œìš© DataFrame ìƒì„±
        submission_df = pd.DataFrame({
            'PassengerId': passenger_ids,
            'Survived': predictions.astype(int)
        })
        
        # download í´ë”ì— ì €ì¥ (ì ˆëŒ€ ê²½ë¡œ ì‚¬ìš©)
        download_dir = Path(__file__).parent.parent / 'download'
        download_dir = download_dir.resolve()  # ì ˆëŒ€ ê²½ë¡œë¡œ ë³€í™˜
        download_dir.mkdir(parents=True, exist_ok=True)
        
        self.logger.info(f"íŒŒì¼ ì €ì¥ ê²½ë¡œ: {download_dir}")
        self.logger.info(f"ê²½ë¡œ ì¡´ì¬ ì—¬ë¶€: {download_dir.exists()}")
        
        # CSV íŒŒì¼ ì €ì¥
        submission_path = download_dir / 'submission.csv'
        try:
            submission_df.to_csv(submission_path, index=False)
            self.logger.info(f"ì œì¶œ íŒŒì¼ ì €ì¥ ì™„ë£Œ: {submission_path}")
            self.logger.info(f"íŒŒì¼ ì¡´ì¬ ì—¬ë¶€: {submission_path.exists()}")
            self.logger.info(f"íŒŒì¼ í¬ê¸°: {submission_path.stat().st_size if submission_path.exists() else 0} bytes")
        except Exception as e:
            self.logger.error(f"CSV íŒŒì¼ ì €ì¥ ì‹¤íŒ¨: {str(e)}", exc_info=True)
            raise
        
        # ëª¨ë¸ íŒŒì¼ ì €ì¥
        model_path = download_dir / f'{best_model_name}_model.pkl'
        try:
            joblib.dump(best_model, model_path)
            self.logger.info(f"ëª¨ë¸ íŒŒì¼ ì €ì¥ ì™„ë£Œ: {model_path}")
            self.logger.info(f"íŒŒì¼ ì¡´ì¬ ì—¬ë¶€: {model_path.exists()}")
            self.logger.info(f"íŒŒì¼ í¬ê¸°: {model_path.stat().st_size if model_path.exists() else 0} bytes")
        except Exception as e:
            self.logger.error(f"ëª¨ë¸ íŒŒì¼ ì €ì¥ ì‹¤íŒ¨: {str(e)}", exc_info=True)
            raise
        
        # ê²°ê³¼ ìš”ì•½ ì €ì¥
        summary_path = download_dir / 'model_summary.txt'
        try:
            with open(summary_path, 'w', encoding='utf-8') as f:
                f.write("=== ëª¨ë¸ í‰ê°€ ê²°ê³¼ ===\n\n")
                for model_name, accuracy in sorted(results.items(), key=lambda x: x[1], reverse=True):
                    model_name_kr = {
                        'logistic_regression': 'ë¡œì§€ìŠ¤í‹± íšŒê·€',
                        'naive_bayes': 'ë‚˜ì´ë¸Œë² ì´ì¦ˆ',
                        'random_forest': 'ëœë¤í¬ë ˆìŠ¤íŠ¸',
                        'lightgbm': 'LightGBM',
                        'svm': 'SVM'
                    }.get(model_name, model_name)
                    f.write(f"{model_name_kr}: {accuracy:.4f}\n")
                f.write(f"\nì„ íƒëœ ëª¨ë¸: {best_model_name} (ì •í™•ë„: {best_accuracy:.4f})\n")
            self.logger.info(f"ê²°ê³¼ ìš”ì•½ ì €ì¥ ì™„ë£Œ: {summary_path}")
            self.logger.info(f"íŒŒì¼ ì¡´ì¬ ì—¬ë¶€: {summary_path.exists()}")
            self.logger.info(f"íŒŒì¼ í¬ê¸°: {summary_path.stat().st_size if summary_path.exists() else 0} bytes")
        except Exception as e:
            self.logger.error(f"ìš”ì•½ íŒŒì¼ ì €ì¥ ì‹¤íŒ¨: {str(e)}", exc_info=True)
            raise
        
        self.logger.info("ğŸ€ğŸ€ ì œì¶œ ì™„ë£Œ")
        return {
            'submission_file': str(submission_path),
            'model_file': str(model_path),
            'summary_file': str(summary_path),
            'best_model': best_model_name,
            'best_accuracy': best_accuracy
        }

 